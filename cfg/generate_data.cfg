data_root = /opt/ply/input/
objects_file_location = /opt/ply/objects.txt
output_root = /opt/ply/test/
chunk_size = 1000
max_in_memory = 80000
num_views_per_object = 20
min_grasps_per_view = 100
max_grasps_per_view = 500
test_views = 2 5 8 13 16

# Hand geometry
hand_geometry_filename = 0
finger_width = 0.01
hand_outer_diameter = 0.12
hand_depth = 0.06
hand_height = 0.02
init_bite = 0.01

# Image geometry
image_geometry_filename = 0
volume_width = 0.10
volume_depth = 0.06
volume_height = 0.02
image_size = 60
image_num_channels = 12

# Point cloud preprocessing
remove_nans = 0
voxel_size = 0.003
reverse_mesh_normals = 1
reverse_view_normals = 1

# Grasp candidate generation
#   num_samples: number of samples to be drawn from the point cloud
#   num_threads: number of CPU threads to be used
#   nn_radius: neighborhood search radius for the local reference frame estimation
#   num_orientations: number of robot hand orientations to evaluate
#   num_finger_placements: number of finger placements to evaluate
#   hand_axes: axes about which the point neighborhood gets rotated (0: approach, 1: binormal, 2: axis)
#              (see https://raw.githubusercontent.com/atenpas/gpd2/master/readme/hand_frame.png)
#   deepen_hand: if the hand is pushed forward onto the object
#   friction_coeff: angle of friction cone in degrees
#   min_viable: minimum number of points required on each side to be antipodal
num_samples = 400
num_threads = 24
nn_radius = 0.01
num_orientations = 8
num_finger_placements = 10
# hand_axes = 0 1 2
# hand_axes = 0
# hand_axes = 1
hand_axes = 2
deepen_hand = 1
friction_coeff = 20
min_viable = 6

plot_samples = 0
